{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "Dieses Jupyter-Notebook-Dokument enthält alles, was zum Trainieren eines generativen adversen Netzwerks erforderlich ist, um Bilder aus dem MNINST- und CIFAR10-Datensatz zu erstellen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "##### Standardbibliotheken\n",
    "- os: ermöglicht Erstellung von Ordnern und Navigation durch die Ordnerstruktur des Projektes\n",
    "- sys: sys.path.append erlaubt das Importieren von Klassen, welche außerhalb definiert sind (im src-Ordner)\n",
    "- torch & torch.nn: Standard Pytorch Klassen\n",
    "- torchvision transforms: Transformation von Tensoren\n",
    "- torchvision.utils save_image: ermöglicht das Abspeichern der Bilder die erzeugt werden\n",
    "\n",
    "\n",
    "##### Custom Imports\n",
    "- classes.gan.XY: importiert die jeweiligen GAN Klassen die im Ordner src/classes/gan definiert sind.\n",
    "- Klassen / Funktionen aus dem Ordner src/utils/ sind selbsterstelle Klassen / Funktionen, welche Code kapseln und so die Lesbarkeit verbessern. Die Dokumentation zu den Klassen / Funktionen findet sich in den entsprechenden Dateien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import datetime\n",
    "\n",
    "# custom imports\n",
    "sys.path.append('../src')\n",
    "from utils.dataset import load_datasets\n",
    "from utils.foldergen import generate_folder\n",
    "from classes.gan.gan import Generator, Discriminator\n",
    "from classes.gan.ganCNN import GeneratorCNN, DiscriminatorCNN\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "datasettype = \"MNIST\" # only option is \"MNIST\"\n",
    "networktype = \"NN\" # select either \"NN\" or \"CNN\"\n",
    "\n",
    "# Train a new network or continue training a previously trained network:\n",
    "continueTraining = False;\n",
    "\n",
    "# learning rate\n",
    "lr = 0.0002\n",
    "\n",
    "# number of epochs\n",
    "num_epochs = 100\n",
    "batch_size = 25\n",
    "\n",
    "hidden_dim = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data\n",
    "\n",
    "Im Folgenden wird die ``transform``-Funktion definiert, mit der die Daten transformiert werden.\n",
    "\n",
    "Danach werden die Ordner erstellt, wo nachher der Output landet, falls diese noch nicht existieren.\n",
    "\n",
    "Zum Schluss werden zwei Datasets und zwei Dataloader erzeugt, einmal mit dem Trainingsdatensatz, einmal mit dem Testdatenssatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datasettype == \"MNIST\":\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                [0.5], [0.5]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "elif datasettype == \"CIFAR10\":\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# create folder structure\n",
    "load_folder = \"load\"\n",
    "output_folder = \"output\"\n",
    "folders = [load_folder, output_folder]\n",
    "generate_folder(folders)\n",
    "\n",
    "dataset_train, loader_train = load_datasets(datasettype, transform, batch_size)\n",
    "dataset_test, loader_test = load_datasets(datasettype, transform, batch_size, train=False, download=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "Der Generator wird als ``Gen`` und der Discriminator als ``Dis`` initialisiert.\n",
    "Die Initialisierung ist abhängig von dem oben gesetzen ``networktype``.\n",
    "\n",
    "Als ``lossFunction`` wird Pytorchs BCELoss() Funktion genutzt.\n",
    "\n",
    "Zum Schluss werden zwei Adam-Optimizer erstellt, jeweils einer für den Generator und einen für den Diskriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "\n",
    "# set image_channels depending on datasettype\n",
    "if datasettype == \"MNIST\":\n",
    "    image_channels = 1\n",
    "    data_dim = 28 * 28\n",
    "elif datasettype == \"CIFAR10\":\n",
    "    image_channels = 3\n",
    "    data_dim = 32 * 32\n",
    "\n",
    "if networktype == \"NN\":\n",
    "    Gen = Generator(g_input_dim= z_dim, g_hidden_dim= hidden_dim, g_output_dim= data_dim * image_channels).to(device)\n",
    "    Dis = Discriminator(d_input_dim= data_dim * image_channels,  d_hidden_dim= hidden_dim).to(device)\n",
    "elif networktype == \"CNN\":\n",
    "    Gen = GeneratorCNN(latent_dim = z_dim, img_channels = image_channels, img_size = data_dim)\n",
    "    Dis = DiscriminatorCNN(img_channels = image_channels, img_size = data_dim)\n",
    "\n",
    "lossFunction = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "Gen_optimizer = torch.optim.Adam(Gen.parameters(), lr=lr)\n",
    "Dis_optimizer = torch.optim.Adam(Dis.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden wird eine Trainingsstep für den Diskriminator beschrieben.\n",
    "\n",
    "Dabei wird zunächst ein Forward-Pass mit echten Bildern aus dem Datensatz durchgeführt. Danach wird der Loss des Diskriminators mit den echten Daten berechnet.\n",
    "\n",
    "Dann wird ein Forward-Pass mit den künstlichen Daten des Generators durchgeführt. Dann wird der Loss des Diskriminators mit den künstlichen Daten berechnet.\n",
    "\n",
    "Beide Losses werden addiert und die Backpropagation findet statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dis_train(x):\n",
    "    Dis.zero_grad()\n",
    "\n",
    "    # flatten tensor if a NN is being used\n",
    "    if networktype == \"NN\":\n",
    "        x = x.view(-1, data_dim * image_channels)\n",
    "    # real data\n",
    "    y_real = torch.ones(batch_size, 1)\n",
    "    x_real, y_real = x.to(device), y_real.to(device)\n",
    "\n",
    "    D_output = Dis(x_real)\n",
    "    D_real_loss = lossFunction(D_output, y_real)\n",
    "\n",
    "    # fake data\n",
    "    z =  torch.randn(batch_size, z_dim).to(device)\n",
    "    x_fake, y_fake = Gen(z), torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "    D_output = Dis(x_fake)\n",
    "    D_fake_loss = lossFunction(D_output, y_fake)\n",
    "\n",
    "    # loss\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    Dis_optimizer.step()\n",
    "\n",
    "    return D_loss.data.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird ein Trainingsstep für den Generator beschrieben.\n",
    "\n",
    "Dabei wird dem Generator eine Zufallsmatrix gegeben, daraus erzeugt der Generator ein Bild.\n",
    "\n",
    "Dieses wird dem Diskriminator gegeben. Der Loss berechnet sich daraus, ob der bzw. wie gut Diskriminator getäuscht werden konnte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen_train(x):\n",
    "    Gen.zero_grad()\n",
    "\n",
    "    z = torch.randn(batch_size, z_dim).to(device)\n",
    "    y = torch.ones(batch_size, 1).to(device)\n",
    "\n",
    "    G_output = Gen(z)\n",
    "    D_output = Dis(G_output)\n",
    "    G_loss = lossFunction(D_output, y)\n",
    "\n",
    "    # loss\n",
    "    G_loss.backward()\n",
    "    Gen_optimizer.step()\n",
    "\n",
    "    return G_loss.data.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model for further training\n",
    "\n",
    "Im Folgenden werden bereits trainierte Modelle des Diskriminators und Generators geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for further training\n",
    "discriminator_file = \"discriminator.pth\"\n",
    "generator_file = \"generator.pth\"\n",
    "\n",
    "# Check if directory and files for discriminator and generator exist\n",
    "if os.path.exists(load_folder) and os.path.isfile(os.path.join(load_folder, discriminator_file)) and os.path.isfile(os.path.join(load_folder, generator_file)) and continueTraining:\n",
    "    Gen = Generator(g_input_dim = z_dim, g_hidden_dim=hidden_dim, g_output_dim = data_dim * image_channels).to(device)\n",
    "    Gen.load_state_dict(torch.load(os.path.join(load_folder, generator_file), map_location=device))\n",
    "\n",
    "    Dis = Discriminator(d_input_dim= data_dim, d_hidden_dim= hidden_dim).to(device)\n",
    "    Dis.load_state_dict(torch.load(os.path.join(load_folder, discriminator_file), map_location=device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Im Folgenden findet das Training der Modelle statt, indem die Trainingssteps des Diskriminators und des Generators aufgerufen werden.\n",
    "\n",
    "Dabei werden die Ergebnisse, also die Bilder und die neuen Modelle in einem Unterornder gespeichert, welcher das Datum und die Uhrzeit tragen. So soll vermieden werden, dass die gespeicherten Modelle und erzeugten Bilder eventuell überschrieben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure if it does not exist\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%d%m-%H%M\")\n",
    "\n",
    "# Create subfolders if they don't exist\n",
    "pictures_folder = os.path.join(output_folder, formatted_time, \"pic\")\n",
    "model_folder = os.path.join(output_folder, formatted_time, \"model\")\n",
    "\n",
    "if not os.path.exists(pictures_folder):\n",
    "    os.makedirs(pictures_folder)\n",
    "\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    D_losses, G_losses = [], []\n",
    "    for batch_idx, (x, _) in enumerate(loader_train):\n",
    "        D_losses.append(Dis_train(x))\n",
    "        G_losses.append(Gen_train(x))\n",
    "\n",
    "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
    "            (epoch), num_epochs, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch % 1 == 0:\n",
    "            test_z = torch.randn(batch_size, z_dim).to(device)\n",
    "            generated = Gen(test_z)\n",
    "\n",
    "            # format output string\n",
    "            formatted_number = \"{:0{}}\".format(epoch, len(str(num_epochs)))\n",
    "\n",
    "            if datasettype == \"CIFAR10\":\n",
    "                save_image(generated.view(generated.size(0), image_channels, 32, 32), pictures_folder + '/' + formatted_number + '.png')\n",
    "            elif datasettype == \"MNIST\":\n",
    "                save_image(generated.view(generated.size(0), image_channels, 28, 28), pictures_folder + '/' + formatted_number + '.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Gen.state_dict(), model_folder + '/' + 'generator.pth')\n",
    "torch.save(Dis.state_dict(), model_folder + '/' + 'discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

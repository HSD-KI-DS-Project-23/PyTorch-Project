{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import datetime\n",
    "\n",
    "# custom imports\n",
    "sys.path.append('../src')\n",
    "from utils.dataset import load_datasets\n",
    "from utils.foldergen import generate_folder\n",
    "from classes.gan.gan import Generator, Discriminator\n",
    "from classes.gan.ganCNN import GeneratorCNN, DiscriminatorCNN\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasettype = \"MNIST\"\n",
    "\n",
    "# Train a new network or continue training a previously trained network:\n",
    "continueTraining = False;\n",
    "\n",
    "# learning rate\n",
    "lr = 0.0002\n",
    "\n",
    "# number of epochs\n",
    "num_epochs = 100\n",
    "batch_size = 25\n",
    "\n",
    "hidden_dim = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datasettype == \"MNIST\":\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),  # create PyTorch Tensor | shape: (channels, height, width)\n",
    "            transforms.Normalize(\n",
    "                [0.5], [0.5]\n",
    "            ),  # convert values to [-1, 1]\n",
    "        ]\n",
    "    )\n",
    "elif datasettype == \"CIFAR10\":\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# create folder structure\n",
    "data_folder = \"data\"\n",
    "load_folder = \"load\"\n",
    "output_folder = \"output\"\n",
    "folders = [data_folder, load_folder, output_folder]\n",
    "generate_folder(folders)\n",
    "\n",
    "dataset_train, loader_train = load_datasets(datasettype, transform, batch_size)\n",
    "dataset_test, loader_test = load_datasets(datasettype, transform, batch_size, train=False, download=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "# automatically calculate the dimension -> does not work with CIFAR10\n",
    "# data_dim = 1\n",
    "# for dimension in range(1, dataset_train.data.ndim):\n",
    "#     data_dim *= dataset_train.data.size(dimension)\n",
    "\n",
    "# set image_channels depending on datasettype\n",
    "if datasettype == \"MNIST\":\n",
    "    image_channels = 0\n",
    "    data_dim = 28 * 28\n",
    "elif datasettype == \"CIFAR10\":\n",
    "    image_channels = 3\n",
    "    data_dim = 32 * 32 * 3\n",
    "\n",
    "# Gen = Generator(g_input_dim= z_dim, g_hidden_dim= hidden_dim, g_output_dim= data_dim,).to(device)\n",
    "# Dis = Discriminator(d_input_dim= data_dim,  d_hidden_dim= hidden_dim).to(device)\n",
    "\n",
    "Gen = GeneratorCNN(latent_dim = z_dim, img_channels = image_channels, img_size = data_dim)\n",
    "Dis = DiscriminatorCNN(img_channels = image_channels, img_size = data_dim)\n",
    "\n",
    "lossFunction = nn.BCELoss()\n",
    "\n",
    "# Optimizers\n",
    "Gen_optimizer = optim.Adam(Gen.parameters(), lr=lr)\n",
    "Dis_optimizer = optim.Adam(Dis.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dis_train(x):\n",
    "    Dis.zero_grad()\n",
    "\n",
    "    # real data\n",
    "    x_real, y_real = x.view(-1, data_dim), torch.ones(batch_size, 1)\n",
    "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
    "\n",
    "    D_output = Dis(x_real)\n",
    "    D_real_loss = lossFunction(D_output, y_real)\n",
    "\n",
    "    # fake data\n",
    "    z =  torch.randn(batch_size, z_dim).to(device)\n",
    "    x_fake, y_fake = Gen(z), torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "    D_output = Dis(x_fake)\n",
    "    D_fake_loss = lossFunction(D_output, y_fake)\n",
    "\n",
    "    # loss\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    Dis_optimizer.step()\n",
    "\n",
    "    return D_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen_train(x):\n",
    "    Gen.zero_grad()\n",
    "\n",
    "    z = torch.randn(batch_size, z_dim).to(device)\n",
    "    y = torch.ones(batch_size, 1).to(device)\n",
    "\n",
    "    G_output = Gen(z)\n",
    "    D_output = Dis(G_output)\n",
    "    G_loss = lossFunction(D_output, y)\n",
    "\n",
    "    # loss\n",
    "    G_loss.backward()\n",
    "    Gen_optimizer.step()\n",
    "\n",
    "    return G_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for further training\n",
    "\n",
    "discriminator_file = \"discriminator.pth\"\n",
    "generator_file = \"generator.pth\"\n",
    "\n",
    "# Check if directory load and files for discriminator and generator exist\n",
    "if os.path.exists(load_folder) and os.path.isfile(os.path.join(load_folder, discriminator_file)) and os.path.isfile(os.path.join(load_folder, generator_file)) and continueTraining:\n",
    "    Gen = Generator(g_input_dim = z_dim, g_hidden_dim=hidden_dim, g_output_dim = data_dim).to(device)\n",
    "    Gen.load_state_dict(torch.load(os.path.join(load_folder, generator_file), map_location=device))\n",
    "\n",
    "    Dis = Discriminator(d_input_dim= data_dim, d_hidden_dim= hidden_dim).to(device)\n",
    "    Dis.load_state_dict(torch.load(os.path.join(load_folder, discriminator_file), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure if it does not exist\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime(\"%d%m-%H%M\")\n",
    "\n",
    "# Create subfolders if they don't exist\n",
    "pictures_folder = os.path.join(output_folder, formatted_time, \"pic\")\n",
    "model_folder = os.path.join(output_folder, formatted_time, \"model\")\n",
    "\n",
    "if not os.path.exists(pictures_folder):\n",
    "    os.makedirs(pictures_folder)\n",
    "\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    D_losses, G_losses = [], []\n",
    "    for batch_idx, (x, _) in enumerate(loader_train):\n",
    "        D_losses.append(Dis_train(x))\n",
    "        G_losses.append(Gen_train(x))\n",
    "\n",
    "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
    "            (epoch), num_epochs, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if epoch % 10 == 0:\n",
    "            test_z = Variable(torch.randn(batch_size, z_dim).to(device))\n",
    "            generated = Gen(test_z)\n",
    "\n",
    "            # format output string\n",
    "            \n",
    "            formatted_number = \"{:0{}}\".format(epoch, len(str(num_epochs)))\n",
    "\n",
    "            save_image(generated.view(generated.size(0), 1, 28, 28), pictures_folder + '/' + formatted_number + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_z = torch.randn(batch_size, z_dim).to(device)\n",
    "    generated = Gen(test_z)\n",
    "\n",
    "    save_image(generated.view(generated.size(0), 1, 28, 28), pictures_folder + '/' + 'final.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Gen.state_dict(), model_folder + '/' + 'generator.pth')\n",
    "torch.save(Dis.state_dict(), model_folder + '/' + 'discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

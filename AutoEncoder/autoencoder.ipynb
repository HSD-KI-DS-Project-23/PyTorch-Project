{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries\n",
        "\n",
        "##### Standardbibliotheken\n",
        "- os: ermöglicht Erstellung von Ordnern und Navigation durch die Ordnerstruktur des Projektes\n",
        "- sys: sys.path.append erlaubt das Importieren von Klassen, welche außerhalb definiert sind (im src-Ordner)\n",
        "- torch & torch.nn: Standard Pytorch Klassen\n",
        "- torchvision datasets & transforms: ermöglicht Import von den Datensets (MNIST & CIFAR10) sowie die Transformation dieser\n",
        "- matplotlib.pyplot: ermöglicht das Plotten der Bilder / Ergebnisse\n",
        "\n",
        "\n",
        "##### Custom Imports\n",
        "- classes.autoencoder.XY: importiert die jeweiligen AutoEncoder Klassen die im Ordner src/classes/autoencoder definiert sind.\n",
        "- Klassen / Funktionen aus dem Ordner src/utils/ sind selbsterstelle Klassen / Funktionen, welche Code kapseln und so die Lesbarkeit verbessern. Die Dokumentation zu den Klassen / Funktionen findet sich in den entsprechenden Dateien\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# custom imports\n",
        "from classes.autoencoder.autoencoder import AutoEncoder\n",
        "from classes.autoencoder.autoencoder4x100 import AutoEncoder4x100\n",
        "from classes.autoencoder.autoencoderCNN import AutoEncoderCNN\n",
        "\n",
        "from utils.foldergen import generate_folder\n",
        "from utils.dataset import load_datasets\n",
        "from utils.tracker import Tracker\n",
        "from utils.drawImgs import view_reconstructed"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Configuration\n",
        "\n",
        "Im Folgenden wird das Gerät konfiguriert auf dem die Berechnungen ausgeführt werden.\n",
        "Zusätzlich lassen sich folgende Parameter konfigurieren:\n",
        "- ``datasettype``: Auswahl zwischen \"MNIST\" oder \"CIFAR10\"\n",
        "- ``continue_training``: Falls False wird das Training von vorne gestartet, falls True wird ein vorher gespeichertes Model aus \"autoencoder.pth\" geladen und weiter trainiert.\n",
        "- ``evaluate``: Option, ob am Ende eine Evaluation statt finden soll\n",
        "\n",
        "- ``num_epochs``: Die Anzahl der Epochen die trainiert werden\n",
        "- ``batch_size``: \\*\n",
        "- ``learning_rate``: Die Lernrate\n",
        "\n",
        "- ``graph_every_epoch``: konfiguriert welche N.te Epoche der Lossgraph erzeugt wird\n",
        "- ``comparision_every_epoch``: konfiguriert wie oft ein Vergleich zwischen Input und Output des Autoencoder angezeigt wird"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "datasettype = \"MNIST\"\n",
        "continue_training = False # Train a new network or continue training a previously trained network\n",
        "evaluate = False\n",
        "\n",
        "# Hyperparameter\n",
        "num_epochs = 4\n",
        "batch_size = 8\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# output settings\n",
        "graph_every_epoch = 1\n",
        "comparision_every_epoch = 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Data\n",
        "\n",
        "Im Folgenden wird die ``transform``-Funktion definiert, mit der die Daten transformiert werden.\n",
        "\n",
        "Danach werden die Ordner erstellt, wo nachher der Output landet, falls diese noch nicht existieren.\n",
        "\n",
        "Zum Schluss werden zwei Datasets und zwei Dataloader erzeugt, einmal mit dem Trainingsdatensatz, einmal mit dem Testdatenssatz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if datasettype == \"MNIST\":\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                [0.5], [0.5]\n",
        "            ), \n",
        "        ]\n",
        "    )\n",
        "elif datasettype == \"CIFAR10\":\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# create folder structure\n",
        "folders = [\"output\", \"save\", \"eval\"]\n",
        "generate_folder(folders)\n",
        "\n",
        "dataset_train, loader_train = load_datasets(datasettype,transform, batch_size)\n",
        "dataset_test, loader_test = load_datasets(datasettype,transform, batch_size, train=False, download=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Network\n",
        "\n",
        "Der Autoencoder wird als ``network`` implementiert.\n",
        "\n",
        "Als ``lossFunction`` wird der Mean Squared Error verwendet.\n",
        "\n",
        "Als ``optimizer`` wird der Adam-Optimizer verwendet, mit der obengesetzen Lernrate und einem ``weight_decay`` von 1e-8 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network = AutoEncoderCNN(datasettype=datasettype).to(device)\n",
        "\n",
        "lossFunction = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate, weight_decay= 1e-8)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model loading\n",
        "\n",
        "Es wird die Trackerklasse implementiert, diese trackt den kompletten Lernprozess des Netwerkes und erzeugt später den Lossplot.\n",
        "Ist ``continue_training`` auf True gesetzt, so wird das bereits trainierte Autoencoder-Model geladen und der Tracker läd die Daten, des vorherigen Trainings.\n",
        "\n",
        "Außerdem wird geladen wie viele Epochen bereits absolviert wurden und die ``start_epoch`` wird entsprechend gesetzt. So wird später das Überschreiben von Bildern / Ergebnissen vermieden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tracker = Tracker()\n",
        "if continue_training:\n",
        "    network = torch.load('autoencoder.pth')\n",
        "    tracker.load(\"data.json\")\n",
        "    start_epoch = tracker.epochs_completed + 1\n",
        "else:\n",
        "    start_epoch = 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training\n",
        "\n",
        "Die Trainingsschleife startet bei ``start_epoch`` und endet bei ``end_epoch`` (=``start_epoch+num_epochs``)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "end_epoch = start_epoch + num_epochs\n",
        "for epoch in range(start_epoch, end_epoch):\n",
        "    total_loss = 0\n",
        "\n",
        "    tracker.epochs_completed += 1\n",
        "    average_loss = 0.0\n",
        "    eval_loss = 0\n",
        "    \n",
        "    for image, label in loader_train:\n",
        "\n",
        "        image = image.to(device)\n",
        "    \n",
        "        # pass image through autoencoder\n",
        "        reconstructed = network(image)\n",
        "\n",
        "        # evaluate loss by comparing reconstructed image with actual image\n",
        "        loss = lossFunction(reconstructed, image)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * batch_size\n",
        "\n",
        "    average_loss += total_loss / 60000\n",
        "    print(epoch, \"/\", end_epoch-1, average_loss)\n",
        "    tracker.y_loss[\"train\"].append(average_loss)\n",
        "\n",
        "    tracker.x_epoch.append(epoch)\n",
        "    tracker.learning_rate.append(learning_rate)\n",
        "    \n",
        "    # Evaluation\n",
        "    network.cpu()\n",
        "    network.eval()\n",
        "    image = image.to('cpu')\n",
        "\n",
        "    reconstructed = network(image)\n",
        "\n",
        "    eval_loss = lossFunction(reconstructed, image)\n",
        "    # print(eval_loss.item())\n",
        "    tracker.y_loss[\"val\"].append(eval_loss.item())\n",
        "\n",
        "    if epoch % comparision_every_epoch == 0:\n",
        "        view_reconstructed(image, reconstructed)\n",
        "        print(label[0].shape)\n",
        "\n",
        "    image = image.to(device)\n",
        "    network.to(device)\n",
        "    network.train()\n",
        "    torch.save(network, f'save/ep{epoch}.pth') # Save model at end of epoch\n",
        "\n",
        "    # plot loss graph every given epoch\n",
        "    if epoch % graph_every_epoch == 0:\n",
        "        tracker.plotLossGraph()\n",
        "\n",
        "# plot loss graph at the end of the last epoch, if it has not been printed yet\n",
        "if not epoch % graph_every_epoch == 0:\n",
        "    tracker.plotLossGraph()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(network, 'autoencoder.pth')\n",
        "tracker.save(\"data.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only works with DFF\n",
        "if evaluate and datasettype == \"MNIST\":\n",
        "    network = torch.load('autoencoder.pth')\n",
        "\n",
        "    dataset_test = datasets.MNIST(\n",
        "        root='../data', train=False, transform=transform, download=False\n",
        "    )\n",
        "\n",
        "    loader_test = torch.utils.data.DataLoader(\n",
        "        dataset=dataset_test, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (image, _) in enumerate(loader_test):\n",
        "            # take image from loader an flatten it\n",
        "            image = image.reshape(-1, 28 * 28).to(device)\n",
        "\n",
        "            # pass (flattened) image through autoencoder\n",
        "            reconstructed = network(image)\n",
        "\n",
        "            # evaluate loss by comparing reconstructed image with actual image\n",
        "            loss = lossFunction(reconstructed, image)\n",
        "\n",
        "            # Show input and reconstructed images side by side\n",
        "            if batch_idx % 1000:\n",
        "                fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "                axes[0].imshow(image[0].reshape(28, 28).to(\"cpu\"), cmap=\"gray\")\n",
        "                axes[0].axis(\"off\")\n",
        "                axes[0].set_title(\"Input Image\")\n",
        "                axes[1].imshow(\n",
        "                    reconstructed[0].detach().to(\"cpu\").numpy().reshape(28, 28), cmap=\"gray\"\n",
        "                )\n",
        "                axes[1].axis(\"off\")\n",
        "                axes[1].set_title(\"Reconstructed Image\")\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(\"eval/\", f\"test_{batch_idx}.png\"))  # Save the figure\n",
        "                plt.show()\n",
        "                plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

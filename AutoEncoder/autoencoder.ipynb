{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# custom imports\n",
        "from classes.autoencoder.autoencoder import AutoEncoder\n",
        "from classes.autoencoder.autoencoder4x100 import AutoEncoder4x100\n",
        "from classes.autoencoder.autoencoderCNN import AutoEncoderCNN\n",
        "\n",
        "from utils.foldergen import generate_folder\n",
        "from utils.dataset import load_datasets\n",
        "from utils.tracker import Tracker\n",
        "from utils.drawImgs import view_reconstructed\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasettype = \"MNIST\"\n",
        "continue_training = False\n",
        "evaluate = False\n",
        "\n",
        "# Hyperparameter\n",
        "num_epochs = 50\n",
        "batch_size = 25\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# output settings\n",
        "graph_every_epoch = 5\n",
        "comparision_every_epoch = 5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5], [0.5]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# create folder structure\n",
        "folders = [\"output\", \"save\", \"eval\"]\n",
        "generate_folder(folders)\n",
        "\n",
        "dataset_train, loader_train = load_datasets(datasettype,transform, batch_size)\n",
        "dataset_test, loader_test = load_datasets(datasettype,transform, batch_size, train=False, download=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "network = AutoEncoderCNN(datasettype=datasettype).to(device)\n",
        "\n",
        "lossFunction = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate, weight_decay= 1e-8)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model loading\n",
        "Load a previous model if ``continue_training`` is set to `True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tracker = Tracker()\n",
        "if continue_training:\n",
        "    network = torch.load('complete.pth')\n",
        "    tracker.load(\"data.json\")\n",
        "    start_epoch = tracker.epochs_completed + 1\n",
        "else:\n",
        "    start_epoch = 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_steps = 0\n",
        "end_epoch = start_epoch + num_epochs\n",
        "for epoch in range(start_epoch, end_epoch):\n",
        "    total_loss = 0\n",
        "    total_loss_eval = 0\n",
        "\n",
        "    tracker.epochs_completed += 1\n",
        "    average_loss = 0.0\n",
        "    average_loss_eval = 0.0\n",
        "    eval_loss = 0\n",
        "    \n",
        "    for image, label in loader_train:\n",
        "        training_steps += 1\n",
        "\n",
        "        reconstructed = network(image.to(device))\n",
        "        \n",
        "        # print(image.shape)\n",
        "        # print(reconstructed.shape)\n",
        "        # pass image through autoencoder\n",
        "        reconstructed = network(image.to(device))\n",
        "\n",
        "        # evaluate loss by comparing reconstructed image with actual image\n",
        "        loss = lossFunction(reconstructed, image)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * batch_size\n",
        "\n",
        "    average_loss += total_loss / 60000\n",
        "    print(epoch, \"/\", end_epoch-1, average_loss)\n",
        "    tracker.y_loss[\"train\"].append(average_loss)\n",
        "\n",
        "    tracker.x_epoch.append(epoch)\n",
        "    tracker.learning_rate.append(learning_rate)\n",
        "    \n",
        "\n",
        "    network.cpu()\n",
        "    network.eval()\n",
        "\n",
        "    reconstructed = network(image)\n",
        "\n",
        "    eval_loss = lossFunction(reconstructed, image)\n",
        "    # print(eval_loss.item())\n",
        "    tracker.y_loss[\"val\"].append(eval_loss.item())\n",
        "\n",
        "    if comparision_every_epoch:\n",
        "        view_reconstructed(image, reconstructed)\n",
        "        print(label[0].shape)\n",
        "\n",
        "    network.to(device)\n",
        "    network.train()\n",
        "    torch.save(network, f'save/ep{epoch}.pth')\n",
        "\n",
        "    if epoch % graph_every_epoch == 0:\n",
        "        tracker.plotLossGraph()\n",
        "\n",
        "if not epoch % 10 == 0:\n",
        "    tracker.plotLossGraph()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(network, 'complete.pth')\n",
        "tracker.save(\"data.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: handle CIFAR10 and test CNN\n",
        "if evaluate:\n",
        "    network = torch.load('complete.pth')\n",
        "\n",
        "    dataset_test = datasets.MNIST(\n",
        "        root='../data', train=False, transform=transform, download=False\n",
        "    )\n",
        "\n",
        "    loader_test = torch.utils.data.DataLoader(\n",
        "        dataset=dataset_test, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (image, _) in enumerate(loader_test):\n",
        "            # take image from loader an flatten it\n",
        "            image = image.reshape(-1, 28 * 28).to(device)\n",
        "\n",
        "            # pass (flattened) image through autoencoder\n",
        "            reconstructed = network(image)\n",
        "\n",
        "            # evaluate loss by comparing reconstructed image with actual image\n",
        "            loss = lossFunction(reconstructed, image)\n",
        "\n",
        "            # Show input and reconstructed images side by side\n",
        "            if batch_idx % 1000:\n",
        "                fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "                axes[0].imshow(image[0].reshape(28, 28).to(\"cpu\"), cmap=\"gray\")\n",
        "                axes[0].axis(\"off\")\n",
        "                axes[0].set_title(\"Input Image\")\n",
        "                axes[1].imshow(\n",
        "                    reconstructed[0].detach().to(\"cpu\").numpy().reshape(28, 28), cmap=\"gray\"\n",
        "                )\n",
        "                axes[1].axis(\"off\")\n",
        "                axes[1].set_title(\"Reconstructed Image\")\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(\"eval/\", f\"test_{batch_idx}.png\"))  # Save the figure\n",
        "                plt.show()\n",
        "                plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

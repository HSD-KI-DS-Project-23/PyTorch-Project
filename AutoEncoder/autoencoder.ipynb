{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# custom imports\n",
        "\n",
        "from classes.autoencoder import AutoEncoder\n",
        "from utils.foldergen import generate_folder\n",
        "from utils.dataset import load_datasets\n",
        "from utils.tracker import Tracker\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter\n",
        "num_epochs = 2\n",
        "batch_size = 25\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Model Settings\n",
        "continue_training = False\n",
        "evaluate = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5], [0.5]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# create folder structure\n",
        "folders = [\"output\", \"save\", \"eval\"]\n",
        "generate_folder(folders)\n",
        "\n",
        "dataset_train, loader_train = load_datasets(transform, batch_size)\n",
        "dataset_test, loader_test = load_datasets(transform, batch_size, False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AE = AutoEncoder().to(device)\n",
        "\n",
        "lossFunction = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(AE.parameters(), lr=learning_rate, weight_decay= 1e-8)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model loading\n",
        "Load a previous model if ``continue_training`` is set to `True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tracker = Tracker()\n",
        "if continue_training:\n",
        "    AE = torch.load('complete.pth')\n",
        "    tracker.load(\"data.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if continue_training:\n",
        "    start_epoch = tracker.epochs_completed + 1\n",
        "else:\n",
        "    start_epoch = 1\n",
        "\n",
        "end_epoch = start_epoch + num_epochs\n",
        "running_loss = 0.0\n",
        "running_corrects = 0.0\n",
        "for epoch in range(start_epoch, end_epoch):\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    tracker.epochs_completed += 1\n",
        "    losses = []\n",
        "    for image, _ in loader:\n",
        "        # take image from loader an flatten it\n",
        "        image = image.reshape(-1, 28 * 28).to(device)\n",
        "\n",
        "        # pass (flattened) image through autoencoder\n",
        "        reconstructed = AE(image)\n",
        "\n",
        "        # evaluate loss by comparing reconstructed image with actual image\n",
        "        loss = lossFunction(reconstructed, image)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "        total_loss += loss.item() * batch_size\n",
        "        count += 1\n",
        "\n",
        "    average_loss = total_loss / count\n",
        "    tracker.y_loss[\"train\"].append(average_loss / 60000)\n",
        "\n",
        "    tracker.x_epoch.append(epoch)\n",
        "    tracker.learning_rate.append(learning_rate)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        tracker.plotLossGraph()\n",
        "\n",
        "        # Show input and reconstructed images side by side\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "        axes[0].imshow(image[0].reshape(28, 28).to(\"cpu\"), cmap=\"gray\")\n",
        "        axes[0].axis(\"off\")\n",
        "        axes[0].set_title(\"Input Image\")\n",
        "        axes[1].imshow(\n",
        "            reconstructed[0].detach().to(\"cpu\").numpy().reshape(28, 28), cmap=\"gray\"\n",
        "        )\n",
        "        axes[1].axis(\"off\")\n",
        "        axes[1].set_title(\"Reconstructed Image\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(\"output\", f\"epoch_{epoch}.png\"))  # Save the figure\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "if not epoch % 10 == 0:\n",
        "    tracker.plotLossGraph()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(AE, 'complete.pth')\n",
        "tracker.save(\"data.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if evaluate:\n",
        "    AE = torch.load('complete.pth')\n",
        "\n",
        "    dataset_test = datasets.MNIST(\n",
        "        root='../data', train=False, transform=transform, download=False\n",
        "    )\n",
        "\n",
        "    loader_test = torch.utils.data.DataLoader(\n",
        "        dataset=dataset_test, batch_size=batch_size, shuffle=False\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (image, _) in enumerate(loader_test):\n",
        "            # take image from loader an flatten it\n",
        "            image = image.reshape(-1, 28 * 28).to(device)\n",
        "\n",
        "            # pass (flattened) image through autoencoder\n",
        "            reconstructed = AE(image)\n",
        "\n",
        "            # evaluate loss by comparing reconstructed image with actual image\n",
        "            loss = lossFunction(reconstructed, image)\n",
        "\n",
        "            # Show input and reconstructed images side by side\n",
        "            if batch_idx % 1000:\n",
        "                fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "                axes[0].imshow(image[0].reshape(28, 28).to(\"cpu\"), cmap=\"gray\")\n",
        "                axes[0].axis(\"off\")\n",
        "                axes[0].set_title(\"Input Image\")\n",
        "                axes[1].imshow(\n",
        "                    reconstructed[0].detach().to(\"cpu\").numpy().reshape(28, 28), cmap=\"gray\"\n",
        "                )\n",
        "                axes[1].axis(\"off\")\n",
        "                axes[1].set_title(\"Reconstructed Image\")\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(os.path.join(\"eval/\", f\"test_{batch_idx}.png\"))  # Save the figure\n",
        "                plt.show()\n",
        "                plt.close()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

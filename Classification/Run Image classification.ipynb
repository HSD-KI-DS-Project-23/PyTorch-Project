{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Von Maximilian Horster und Yanik Plutte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Generall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Cuda is available:',torch.cuda.is_available(),'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = (8*4*4)\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 2\n",
    "learn_rate = 0.0003\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure if it does not exist\n",
    "folder_path = \"../../data/\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "\n",
    "#MNIST Dataset\n",
    "    #Create Folder, transorm to Tensor\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=folder_path, train=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.01307),(0.3081))]), download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=folder_path, train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.01307),(0.3081))])\n",
    ")\n",
    "\n",
    "#Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True #use shuffle to not let the network train on the order of data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "#show MNIST Dataset\n",
    "\n",
    "# figure= plt.figure(figsize=(10,8))\n",
    "# spalten, zeilen = 5,5\n",
    "# for i in range(1,spalten*zeilen+1):\n",
    "#     sample_idx = torch.randint(len(train_dataset),size=(1,)).item()\n",
    "#     image , label = train_dataset[sample_idx]\n",
    "#     figure.add_subplot(spalten,zeilen,i)\n",
    "#     plt.title(label, weight='bold')\n",
    "#     plt.imshow(image.squeeze(), cmap='gray')\n",
    "# plt.subplots_adjust(wspace=0.3,hspace=0.6)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary models for classification\n",
    "    # reduce complexitiy and mass of code\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from classes.autoencoder.autoencoderCNN import AutoEncoder\n",
    "from classes.imageclassification.classification import MNIST_Classification_Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'AutoEncoderCNN' on <module 'classes.autoencoder.autoencoderCNN' from 'c:\\\\Users\\\\maxim\\\\Documents\\\\GitHub\\\\PyTorch-Project\\\\Classification\\\\../src\\\\classes\\\\autoencoder\\\\autoencoderCNN.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Define AutoEncoder Model and use encoder\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ModelAE \u001b[39m=\u001b[39m AutoEncoder()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m ModelAE \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mep40.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m, map_location\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m      6\u001b[0m ModelAE\u001b[39m.\u001b[39meval()\n\u001b[0;32m      8\u001b[0m trained_encoder \u001b[39m=\u001b[39m ModelAE\u001b[39m.\u001b[39mencode\n",
      "File \u001b[1;32mc:\\Users\\maxim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[0;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[0;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maxim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\maxim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1165\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m mod_name \u001b[39m=\u001b[39m load_module_mapping\u001b[39m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfind_class(mod_name, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'AutoEncoderCNN' on <module 'classes.autoencoder.autoencoderCNN' from 'c:\\\\Users\\\\maxim\\\\Documents\\\\GitHub\\\\PyTorch-Project\\\\Classification\\\\../src\\\\classes\\\\autoencoder\\\\autoencoderCNN.py'>"
     ]
    }
   ],
   "source": [
    "#Define AutoEncoder Model and use encoder\n",
    "\n",
    "ModelAE = AutoEncoder().to(device)\n",
    "ModelAE = torch.load(\"ep40.pth\", map_location=device)\n",
    "\n",
    "ModelAE.eval()\n",
    "\n",
    "trained_encoder = ModelAE.encode\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Image classification model \n",
    "\n",
    "Model_Classifier = MNIST_Classification_Class(input_size, hidden_dim).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  6.0 Function: View Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classifications(img,pred):\n",
    "    pred = pred.cpu().data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(6,9), ncols=2) \n",
    "    ax1.imshow(img.resize_(1, 28, 28).cpu().numpy().squeeze())\n",
    "    ax1.set_title('Original MNIST Image')\n",
    "    \n",
    "    bars = ax2.barh(np.arange(10), pred)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))               #Create bar graph to display prediction probability\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    for bar, val in zip(bars, pred):\n",
    "        if not (val < 0.3):\n",
    "            ax2.text(val, bar.get_y() + bar.get_height() / 2, round(val, 2), va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model / Continue Training\n",
    "continue_training = True\n",
    "\n",
    "PATH = \"classification_model.pth\"\n",
    "\n",
    "if continue_training:\n",
    "    ModelClassification = torch.load(PATH).to(device)\n",
    "\n",
    "#criterion / lf\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(params=Model_Classifier.parameters(),lr=learn_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_id, (Bild,Label) in enumerate(train_loader):\n",
    "        Bild = Bild.to(device)\n",
    "        Label = Label.to(device)\n",
    "\n",
    "        OutputEncoder = trained_encoder(Bild)\n",
    "        OutputEncoder = OutputEncoder.to(device)\n",
    "        OutputEncoder = OutputEncoder.view(OutputEncoder.size(0),-1)\n",
    "\n",
    "        output = Model_Classifier(OutputEncoder)\n",
    "\n",
    "        loss = criterion(output,Label)\n",
    "\n",
    "        if batch_id %512 == 0:\n",
    "            print('Image:',batch_id+1,'of',60000/batch_size,'in Epoche:',epoch+1,'// Loss: %.5f ' % loss)\n",
    "            # view_classifications(Bild[0].cpu().view(1,28,28),output[0])\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoche:',epoch+1, 'Loss: %.5f ' % loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Save Model Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Model_Classifier,PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusuion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = torch.zeros(batch_size)\n",
    "# pred_list = torch.zeros(batch_size)\n",
    "\n",
    "# print(label_list, pred_list)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data,target in test_dataset:\n",
    "#         data = data.reshape(-1,28,28).to(device)\n",
    "#         target = target.to(device)\n",
    "\n",
    "#         outconf= model1(data)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = torch.load(FILE)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_id, (data,target) in enumerate(test_loader):\n",
    "#         data = data.reshape(-1,28*28).to(device)  #[100, 1,28,28] > [100,734] ?\n",
    "#         target = target.to(device)\n",
    "        \n",
    "#         output = model1(data) #was macht out?\n",
    "#         loss = criterion(output,target) #hier out?!\n",
    "\n",
    "#         view_classifications(data[0].view(1,28,28),output[0])\n",
    "#         print('Batch in Epoche ',batch_id+1, 'Loss: %.5f ' % loss)\n",
    "\n",
    "#     print('Epoche:',epoch+1, 'Loss: %.5f ' % loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Von Maximilian Horster und Yanik Plutte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Libaries\n",
    "\n",
    "##### Standardbibliotheken\n",
    "- os: ermöglicht Erstellung von Ordnern und Navigation durch die Ordnerstruktur des Projektes\n",
    "- sys: sys.path.append erlaubt das Importieren von Klassen, welche außerhalb definiert sind (im src-Ordner)\n",
    "- torch & torch.nn: Standard Pytorch Klassen\n",
    "- torchvision datasets & transforms: ermöglicht Import von den Datensets (MNIST & CIFAR10) sowie die Transformation dieser\n",
    "- matplotlib.pyplot: ermöglicht das Plotten der Bilder / Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 General\n",
    "\n",
    "##### Gibt aus ob Cuda verfügbar ist oder der CPU genutzt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cuda is available:',torch.cuda.is_available(),'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Hyperparameters\n",
    "\n",
    "##### Hyperparameter zur Anpassung des Netztes sowie Parameter im Training-Loop\n",
    "\n",
    "##### ``input_size``: Eingabegröße in die erste Schicht des Netzwerkes\n",
    "##### ``hidden_dim``: Dimensionsgröße der Hidden Layer\n",
    "##### ``batch_size``: \n",
    "##### ``num_epochs``: Anzahl der zu trainierenden Epochen\n",
    "##### ``learn_rate``: Lernrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = (8*4*4)\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 2\n",
    "learn_rate = 0.0003\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Load Data\n",
    "#####\n",
    "\n",
    "- Erstellen der Ordnerstruktur falls diese nicht existiert\n",
    "- Download des Datensatzes, Aufteilung in Train=True und Train=False\n",
    "- Definition des Data_Loaders, Aufteilung in Train und Test Daten\n",
    "- Nutzen von \"shuffle\" um eine Anpassung des Netzwerkes an die Reihenfolge der Daten zu vermeiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure if it does not exist\n",
    "folder_path = \"../../data/\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "\n",
    "#MNIST Dataset\n",
    "    #Create Folder, transorm to Tensor\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=folder_path, train=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.01307),(0.3081))]), download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=folder_path, train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.01307),(0.3081))])\n",
    ")\n",
    "\n",
    "#Data Loader in Training\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True #use shuffle to not let the network train on the order of data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "#show MNIST Dataset\n",
    "\n",
    "# figure= plt.figure(figsize=(10,8))\n",
    "# spalten, zeilen = 5,5\n",
    "# for i in range(1,spalten*zeilen+1):\n",
    "#     sample_idx = torch.randint(len(train_dataset),size=(1,)).item()\n",
    "#     image , label = train_dataset[sample_idx]\n",
    "#     figure.add_subplot(spalten,zeilen,i)\n",
    "#     plt.title(label, weight='bold')\n",
    "#     plt.imshow(image.squeeze(), cmap='gray')\n",
    "# plt.subplots_adjust(wspace=0.3,hspace=0.6)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Classes\n",
    "\n",
    "##### Import von Klassen\n",
    "\n",
    "- Import des CNN AutoEncoders aus src\n",
    "- Import des Klassifizierungsnetzwerkes aus src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary models for classification\n",
    "    # reduce complexitiy and mass of code\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from classes.autoencoder.autoencoderCNN import AutoEncoderCNN\n",
    "from classes.imageclassification.classification import MNIST_Classification_Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load AE Model\n",
    "\n",
    "#####\n",
    "- Initiierung des ``AutoEncoders`` als Model\n",
    "- Laden des trainierten (gewichtangepassten) Netzes über ``torch.load``\n",
    "\n",
    "- Auswahl des ``Encoder`` des AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define AutoEncoder Model and use encoder\n",
    "\n",
    "ModelAE = AutoEncoderCNN().to(device)\n",
    "ModelAE = torch.load(\"ep40.pth\", map_location=device)\n",
    "\n",
    "ModelAE.eval()\n",
    "\n",
    "trained_encoder = ModelAE.encode\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load Classification Model\n",
    "\n",
    "#####\n",
    "- Initiieren der ``Classification_Class`` als Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Image classification model \n",
    "\n",
    "Model_Classifier = MNIST_Classification_Class(input_size, hidden_dim).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  6.0 Function: View Predictions\n",
    "\n",
    "#####\n",
    "- Funktion zur Ausgabe des zu klassifizierenden Bildes und der Predictions des Netzwerkes als Balkendiagramm über 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classifications(img,pred):\n",
    "    pred = pred.cpu().data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(6,9), ncols=2) \n",
    "    ax1.imshow(img.resize_(1, 28, 28).cpu().numpy().squeeze())\n",
    "    ax1.set_title('Original MNIST Image')\n",
    "    \n",
    "    bars = ax2.barh(np.arange(10), pred)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))               #Create bar graph to display prediction probability\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    for bar, val in zip(bars, pred):\n",
    "        if not (val < 0.3):\n",
    "            ax2.text(val, bar.get_y() + bar.get_height() / 2, round(val, 2), va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Training\n",
    "\n",
    "##### \n",
    "- Abfrage nach fortführen des Trainings mit bereits trainierten Netzen - anschließender load des Netzes\n",
    "- ``CrossEntropyLoss`` als Verlustfunktion\n",
    "- Als Optimizer wird ``Adam`` mit der in den Hyperparametern festgelegten Lernrate\n",
    "- for-Schleife für definierte Anzahl der ``Epochen``\n",
    "- for schleife für definierte ``Batch_Size``\n",
    "\n",
    "- Laden des Bildes sowie des ``Labels`` über den ``Train_Loader``\n",
    "- Durchlaufen des Bildes durch ``AutoEncoder`` und im folgenden durch den ``Classifier``\n",
    "\n",
    "- Berechnung des Loss durch die ``Verlustfunktion`` anhand des Übergebenen Output (Prediction) und des Label aus dem Trainingsdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model / Continue Training\n",
    "continue_training = True\n",
    "\n",
    "PATH = \"classification_model.pth\"\n",
    "\n",
    "if continue_training:\n",
    "    ModelClassification = torch.load(PATH).to(device)\n",
    "\n",
    "#criterion / lf\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(params=Model_Classifier.parameters(),lr=learn_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_id, (Bild,Label) in enumerate(train_loader):\n",
    "        Bild = Bild.to(device)\n",
    "        Label = Label.to(device)\n",
    "\n",
    "        OutputEncoder = trained_encoder(Bild)\n",
    "        OutputEncoder = OutputEncoder.to(device)\n",
    "        OutputEncoder = OutputEncoder.view(OutputEncoder.size(0),-1)\n",
    "\n",
    "        output = Model_Classifier(OutputEncoder)\n",
    "\n",
    "        loss = criterion(output,Label)\n",
    "\n",
    "        if batch_id %512 == 0:\n",
    "            print('Image:',batch_id+1,'of',60000/batch_size,'in Epoche:',epoch+1,'// Loss: %.5f ' % loss)\n",
    "            # view_classifications(Bild[0].cpu().view(1,28,28),output[0])\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoche:',epoch+1, 'Loss: %.5f ' % loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Save Model Neural Network\n",
    "\n",
    "#####\n",
    "- Speichern des Model um antrainierte Gewichte zu sichern\n",
    "- Name der Datei ist als Variable PATH definiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Model_Classifier,PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusuion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = torch.zeros(batch_size)\n",
    "# pred_list = torch.zeros(batch_size)\n",
    "\n",
    "# print(label_list, pred_list)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data,target in test_dataset:\n",
    "#         data = data.reshape(-1,28,28).to(device)\n",
    "#         target = target.to(device)\n",
    "\n",
    "#         outconf= model1(data)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = torch.load(FILE)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_id, (data,target) in enumerate(test_loader):\n",
    "#         data = data.reshape(-1,28*28).to(device)  #[100, 1,28,28] > [100,734] ?\n",
    "#         target = target.to(device)\n",
    "        \n",
    "#         output = model1(data) #was macht out?\n",
    "#         loss = criterion(output,target) #hier out?!\n",
    "\n",
    "#         view_classifications(data[0].view(1,28,28),output[0])\n",
    "#         print('Batch in Epoche ',batch_id+1, 'Loss: %.5f ' % loss)\n",
    "\n",
    "#     print('Epoche:',epoch+1, 'Loss: %.5f ' % loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

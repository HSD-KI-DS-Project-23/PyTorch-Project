{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Von Maximilian Horster und Yanik Plutte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Generall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cuda is available:',torch.cuda.is_available(),'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = (8*4*4)\n",
    "hidden_dim = 128\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 2\n",
    "learn_rate = 0.0003\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder structure if it does not exist\n",
    "folder_path = \"../../data/\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "\n",
    "#MNIST Dataset\n",
    "    #Create Folder, transorm to Tensor\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=folder_path, train=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.01307),(0.3081))]), download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=folder_path, train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.01307),(0.3081))])\n",
    ")\n",
    "\n",
    "#Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True #use shuffle to not let the network train on the order of data\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "#show MNIST Dataset\n",
    "\n",
    "# figure= plt.figure(figsize=(10,8))\n",
    "# spalten, zeilen = 5,5\n",
    "# for i in range(1,spalten*zeilen+1):\n",
    "#     sample_idx = torch.randint(len(train_dataset),size=(1,)).item()\n",
    "#     image , label = train_dataset[sample_idx]\n",
    "#     figure.add_subplot(spalten,zeilen,i)\n",
    "#     plt.title(label, weight='bold')\n",
    "#     plt.imshow(image.squeeze(), cmap='gray')\n",
    "# plt.subplots_adjust(wspace=0.3,hspace=0.6)\n",
    "# plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary models for classification\n",
    "    # reduce complexitiy and mass of code\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from classes.autoencoder.autoencoderCNN import AutoEncoderCNN\n",
    "from classes.imageclassification.classification import MNIST_Classification_Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define AutoEncoder Model and use encoder\n",
    "\n",
    "ModelAE = AutoEncoderCNN().to(device)\n",
    "ModelAE = torch.load(\"ep40.pth\", map_location=device)\n",
    "\n",
    "ModelAE.eval()\n",
    "\n",
    "trained_encoder = ModelAE.encode\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Load Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Image classification model \n",
    "\n",
    "Model_Classifier = MNIST_Classification_Class(input_size, hidden_dim).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  6.0 Function: View Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classifications(img,pred):\n",
    "    pred = pred.cpu().data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(6,9), ncols=2) \n",
    "    ax1.imshow(img.resize_(1, 28, 28).cpu().numpy().squeeze())\n",
    "    ax1.set_title('Original MNIST Image')\n",
    "    \n",
    "    bars = ax2.barh(np.arange(10), pred)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))               #Create bar graph to display prediction probability\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    for bar, val in zip(bars, pred):\n",
    "        if not (val < 0.3):\n",
    "            ax2.text(val, bar.get_y() + bar.get_height() / 2, round(val, 2), va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model / Continue Training\n",
    "continue_training = True\n",
    "\n",
    "PATH = \"classification_model.pth\"\n",
    "\n",
    "if continue_training:\n",
    "    ModelClassification = torch.load(PATH).to(device)\n",
    "\n",
    "#criterion / lf\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(params=Model_Classifier.parameters(),lr=learn_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_id, (Bild,Label) in enumerate(train_loader):\n",
    "        Bild = Bild.to(device)\n",
    "        Label = Label.to(device)\n",
    "\n",
    "        OutputEncoder = trained_encoder(Bild)\n",
    "        OutputEncoder = OutputEncoder.to(device)\n",
    "        OutputEncoder = OutputEncoder.view(OutputEncoder.size(0),-1)\n",
    "\n",
    "        output = Model_Classifier(OutputEncoder)\n",
    "\n",
    "        loss = criterion(output,Label)\n",
    "\n",
    "        if batch_id %512 == 0:\n",
    "            print('Image:',batch_id+1,'of',60000/batch_size,'in Epoche:',epoch+1,'// Loss: %.5f ' % loss)\n",
    "            # view_classifications(Bild[0].cpu().view(1,28,28),output[0])\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('Epoche:',epoch+1, 'Loss: %.5f ' % loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Save Model Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Model_Classifier,PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusuion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = torch.zeros(batch_size)\n",
    "# pred_list = torch.zeros(batch_size)\n",
    "\n",
    "# print(label_list, pred_list)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data,target in test_dataset:\n",
    "#         data = data.reshape(-1,28,28).to(device)\n",
    "#         target = target.to(device)\n",
    "\n",
    "#         outconf= model1(data)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = torch.load(FILE)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_id, (data,target) in enumerate(test_loader):\n",
    "#         data = data.reshape(-1,28*28).to(device)  #[100, 1,28,28] > [100,734] ?\n",
    "#         target = target.to(device)\n",
    "        \n",
    "#         output = model1(data) #was macht out?\n",
    "#         loss = criterion(output,target) #hier out?!\n",
    "\n",
    "#         view_classifications(data[0].view(1,28,28),output[0])\n",
    "#         print('Batch in Epoche ',batch_id+1, 'Loss: %.5f ' % loss)\n",
    "\n",
    "#     print('Epoche:',epoch+1, 'Loss: %.5f ' % loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
